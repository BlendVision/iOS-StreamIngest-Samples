// swift-interface-format-version: 1.0
// swift-compiler-version: Apple Swift version 5.9.2 (swiftlang-5.9.2.2.56 clang-1500.1.0.2.5)
// swift-module-flags: -target arm64-apple-tvos12.0-simulator -enable-objc-interop -enable-library-evolution -swift-version 5 -enforce-exclusivity=checked -O -module-name HaishinKit
// swift-module-flags-ignorable: -enable-upcoming-feature ExistentialAny -enable-bare-slash-regex
import AVFAudio
import AVFoundation
import Accelerate
import AudioUnit
import CoreAudio
import CoreFoundation
import CoreImage
import CoreMedia
import CoreVideo
import Foundation
@_exported import HaishinKit
import Logboard
import MetalKit
import Network
import QuartzCore
import Swift
import UIKit
import VideoToolbox
import _Concurrency
import _StringProcessing
import _SwiftConcurrencyShims
public enum IOVideoUnitError : Swift.Error {
  case failedToAttach(error: (any Swift.Error)?)
  case failedToCreate(status: Darwin.OSStatus)
  case failedToPrepare(status: Darwin.OSStatus)
  case failedToFlame(status: Darwin.OSStatus)
  case failedToSetOption(status: Darwin.OSStatus, option: HaishinKit.VTSessionOption)
}
@_hasMissingDesignatedInitializers final public class RTMPSharedObject : HaishinKit.EventDispatcher {
  public static func getRemote(withName: Swift.String, remotePath: Swift.String, persistence: Swift.Bool) -> HaishinKit.RTMPSharedObject
  final public let objectEncoding: HaishinKit.RTMPObjectEncoding
  final public var data: [Swift.String : Any?] {
    get
  }
  final public func setProperty(_ name: Swift.String, _ value: Any?)
  final public func connect(_ rtmpConnection: HaishinKit.RTMPConnection)
  final public func clear()
  final public func close()
  @objc deinit
}
extension HaishinKit.RTMPSharedObject : Swift.CustomDebugStringConvertible {
  final public var debugDescription: Swift.String {
    get
  }
}
public struct SoundTransform {
  public static let defaultVolume: Swift.Float
  public static let defaultPan: Swift.Float
  public var volume: Swift.Float
  public var pan: Swift.Float
}
extension HaishinKit.SoundTransform : Swift.CustomDebugStringConvertible {
  public var debugDescription: Swift.String {
    get
  }
}
public let kASUndefined: HaishinKit.ASUndefined
public typealias ASObject = [Swift.String : Any?]
public struct ASUndefined : Swift.CustomStringConvertible {
  public var description: Swift.String {
    get
  }
}
public struct ASTypedObject {
  public typealias TypedObjectDecoder = (_ type: Swift.String, _ data: HaishinKit.ASObject) throws -> Any
  public static func register(typeNamed name: Swift.String, decoder: @escaping HaishinKit.ASTypedObject.TypedObjectDecoder)
  public static func register<T>(type: T.Type, named name: Swift.String) where T : Swift.Decodable
  public static func unregister(typeNamed name: Swift.String)
}
public struct ASArray {
  public var length: Swift.Int {
    get
  }
  public init(count: Swift.Int)
  public init(data: [Any?])
}
extension HaishinKit.ASArray : Swift.ExpressibleByArrayLiteral {
  public init(arrayLiteral elements: Any?...)
  public subscript(i: Any) -> Any? {
    get
    set
  }
  public typealias ArrayLiteralElement = Any?
}
extension HaishinKit.ASArray : Swift.CustomDebugStringConvertible {
  public var debugDescription: Swift.String {
    get
  }
}
extension HaishinKit.ASArray : Swift.Equatable {
  public static func == (lhs: HaishinKit.ASArray, rhs: HaishinKit.ASArray) -> Swift.Bool
}
public struct ASXMLDocument : Swift.CustomStringConvertible {
  public var description: Swift.String {
    get
  }
  public init(data: Swift.String)
}
extension HaishinKit.ASXMLDocument : Swift.Equatable {
  public static func == (lhs: HaishinKit.ASXMLDocument, rhs: HaishinKit.ASXMLDocument) -> Swift.Bool
}
public struct ASXML : Swift.CustomStringConvertible {
  public var description: Swift.String {
    get
  }
  public init(data: Swift.String)
}
extension HaishinKit.ASXML : Swift.Equatable {
  public static func == (lhs: HaishinKit.ASXML, rhs: HaishinKit.ASXML) -> Swift.Bool
}
public protocol TSReaderDelegate : AnyObject {
  func reader(_ reader: HaishinKit.TSReader, id: Swift.UInt16, didRead formatDescription: CoreMedia.CMFormatDescription)
  func reader(_ reader: HaishinKit.TSReader, id: Swift.UInt16, didRead sampleBuffer: CoreMedia.CMSampleBuffer)
}
public class TSReader {
  weak public var delegate: (any HaishinKit.TSReaderDelegate)?
  public init()
  public func read(_ data: Foundation.Data) -> Swift.Int
  public func clear()
  @objc deinit
}
@objc @_Concurrency.MainActor(unsafe) public class MTHKView : MetalKit.MTKView {
  @_Concurrency.MainActor(unsafe) public var videoGravity: AVFoundation.AVLayerVideoGravity
  @available(tvOS 17.0, *)
  @_Concurrency.MainActor(unsafe) public var isCaptureVideoPreviewEnabled: Swift.Bool {
    get
    set
  }
  @_Concurrency.MainActor(unsafe) @objc dynamic public init(frame: CoreFoundation.CGRect)
  @_Concurrency.MainActor(unsafe) @objc required dynamic public init(coder aDecoder: Foundation.NSCoder)
  @_Concurrency.MainActor(unsafe) @objc override dynamic open func awakeFromNib()
  @objc deinit
}
extension HaishinKit.MTHKView : HaishinKit.IOStreamDrawable {
  @_Concurrency.MainActor(unsafe) public func attachStream(_ stream: HaishinKit.IOStream?)
  @_Concurrency.MainActor(unsafe) public func enqueue(_ sampleBuffer: CoreMedia.CMSampleBuffer?)
}
extension HaishinKit.MTHKView : MetalKit.MTKViewDelegate {
  @_Concurrency.MainActor(unsafe) @objc dynamic public func mtkView(_ view: MetalKit.MTKView, drawableSizeWillChange size: CoreFoundation.CGSize)
  @_Concurrency.MainActor(unsafe) @objc dynamic public func draw(in view: MetalKit.MTKView)
}
@available(*, deprecated, renamed: "IOStreamDelegate")
public typealias NetStreamDelegate = HaishinKit.IOStreamDelegate
public protocol IOStreamDelegate : AnyObject {
  func stream(_ stream: HaishinKit.IOStream, didOutput audio: AVFAudio.AVAudioBuffer, when: AVFAudio.AVAudioTime)
  func stream(_ stream: HaishinKit.IOStream, didOutput video: CoreMedia.CMSampleBuffer)
  @available(tvOS 17.0, *)
  func stream(_ stream: HaishinKit.IOStream, sessionWasInterrupted session: AVFoundation.AVCaptureSession, reason: AVFoundation.AVCaptureSession.InterruptionReason?)
  @available(tvOS 17.0, *)
  func stream(_ stream: HaishinKit.IOStream, sessionInterruptionEnded session: AVFoundation.AVCaptureSession)
  func stream(_ stream: HaishinKit.IOStream, videoErrorOccurred error: HaishinKit.IOVideoUnitError)
  func stream(_ stream: HaishinKit.IOStream, audioErrorOccurred error: HaishinKit.IOAudioUnitError)
  func streamDidOpen(_ stream: HaishinKit.IOStream)
}
@available(*, deprecated, renamed: "IOStream")
public typealias NetStream = HaishinKit.IOStream
@objc @_inheritsConvenienceInitializers open class IOStream : ObjectiveC.NSObject {
  public enum ReadyState : Swift.Equatable {
    public static func == (lhs: HaishinKit.IOStream.ReadyState, rhs: HaishinKit.IOStream.ReadyState) -> Swift.Bool
    case initialized
    case open
    case play
    case playing
    case publish
    case publishing(muxer: any HaishinKit.IOMuxer)
    case closed
  }
  final public let lockQueue: Dispatch.DispatchQueue
  public var bitrateStrategy: any HaishinKit.IOStreamBitRateStrategyConvertible {
    get
    set
  }
  public var isMonitoringEnabled: Swift.Bool {
    get
    set
  }
  public var context: CoreImage.CIContext {
    get
    set
  }
  public var torch: Swift.Bool {
    get
    set
  }
  public var frameRate: Swift.Float64 {
    get
    set
  }
  @available(tvOS 17.0, iOS 13.0, *)
  public var isMultiCamSessionEnabled: Swift.Bool {
    get
    set
  }
  @available(tvOS 17.0, *)
  public var sessionPreset: AVFoundation.AVCaptureSession.Preset {
    get
    set
  }
  @available(*, deprecated, renamed: "videoMixerSettings")
  public var multiCamCaptureSettings: HaishinKit.IOVideoMixerSettings {
    get
    set
  }
  public var videoMixerSettings: HaishinKit.IOVideoMixerSettings {
    get
    set
  }
  public var hasAudio: Swift.Bool {
    get
    set
  }
  public var hasVideo: Swift.Bool {
    get
    set
  }
  public var audioSettings: HaishinKit.AudioCodecSettings {
    get
    set
  }
  public var videoSettings: HaishinKit.VideoCodecSettings {
    get
    set
  }
  public var videoInputFormat: CoreMedia.CMVideoFormatDescription? {
    get
  }
  public var audioInputFormat: AVFAudio.AVAudioFormat? {
    get
  }
  public var isRecording: Swift.Bool {
    get
  }
  public var soundTransform: HaishinKit.SoundTransform {
    get
    set
  }
  @objc dynamic public var currentFPS: Swift.UInt16 {
    get
  }
  weak public var delegate: (any HaishinKit.IOStreamDelegate)?
  public var drawable: (any HaishinKit.IOStreamDrawable)? {
    get
    set
  }
  public var readyState: HaishinKit.IOStream.ReadyState {
    get
    set
  }
  @objc override dynamic public init()
  @available(tvOS 17.0, *)
  @available(*, deprecated, renamed: "attachCamera(_:channel:configuration:)")
  public func attachCamera(_ device: AVFoundation.AVCaptureDevice?, onError: ((_ error: any Swift.Error) -> Swift.Void)? = nil)
  @available(iOS 13.0, tvOS 17.0, *)
  @available(*, deprecated, renamed: "attachCamera(_:channel:configuration:)")
  public func attachMultiCamera(_ device: AVFoundation.AVCaptureDevice?, onError: ((_ error: any Swift.Error) -> Swift.Void)? = nil)
  @available(tvOS 17.0, *)
  public func attachCamera(_ device: AVFoundation.AVCaptureDevice?, channel: Swift.UInt8 = 0, configuration: HaishinKit.IOVideoCaptureConfigurationBlock? = nil)
  @available(tvOS 17.0, *)
  public func videoCapture(for channel: Swift.UInt8) -> HaishinKit.IOVideoCaptureUnit?
  @available(tvOS 17.0, *)
  public func attachAudio(_ device: AVFoundation.AVCaptureDevice?, automaticallyConfiguresApplicationAudioSession: Swift.Bool = false, onError: ((_ error: any Swift.Error) -> Swift.Void)? = nil)
  public func append(_ sampleBuffer: CoreMedia.CMSampleBuffer)
  public func append(_ audioBuffer: AVFAudio.AVAudioBuffer, when: AVFAudio.AVAudioTime)
  public func registerVideoEffect(_ effect: HaishinKit.VideoEffect) -> Swift.Bool
  public func unregisterVideoEffect(_ effect: HaishinKit.VideoEffect) -> Swift.Bool
  public func startRecording(_ delegate: any HaishinKit.IORecorderDelegate, settings: [AVFoundation.AVMediaType : [Swift.String : Any]] = IORecorder.defaultOutputSettings)
  public func stopRecording()
  open func readyStateWillChange(to readyState: HaishinKit.IOStream.ReadyState)
  open func readyStateDidChange(to readyState: HaishinKit.IOStream.ReadyState)
  @objc deinit
}
extension HaishinKit.IOStream : HaishinKit.IOScreenCaptureUnitDelegate {
  public func session(_ session: any HaishinKit.IOScreenCaptureUnit, didOutput pixelBuffer: CoreVideo.CVPixelBuffer, presentationTime: CoreMedia.CMTime)
}
@objc public class IOUIScreenCaptureUnit : ObjectiveC.NSObject, HaishinKit.IOScreenCaptureUnit {
  public var enabledScale: Swift.Bool
  public var afterScreenUpdates: Swift.Bool
  public var preferredFramesPerSecond: Swift.Int
  public var attributes: [Foundation.NSString : ObjectiveC.NSObject] {
    get
  }
  weak public var delegate: (any HaishinKit.IOScreenCaptureUnitDelegate)?
  public var isRunning: HaishinKit.Atomic<Swift.Bool> {
    get
  }
  public init(shared: UIKit.UIApplication)
  public init(viewToCapture: UIKit.UIView)
  @objc public func onScreen(_ displayLink: QuartzCore.CADisplayLink)
  @objc deinit
}
extension HaishinKit.IOUIScreenCaptureUnit : HaishinKit.Running {
  public func startRunning()
  public func stopRunning()
}
public protocol TSWriterDelegate : AnyObject {
  func writer(_ writer: HaishinKit.TSWriter, didRotateFileHandle timestamp: CoreMedia.CMTime)
  func writer(_ writer: HaishinKit.TSWriter, didOutput data: Foundation.Data)
}
final public class TSWriter {
  public static let defaultPATPID: Swift.UInt16
  public static let defaultPMTPID: Swift.UInt16
  public static let defaultVideoPID: Swift.UInt16
  public static let defaultAudioPID: Swift.UInt16
  public static let defaultSegmentDuration: Swift.Double
  weak final public var delegate: (any HaishinKit.TSWriterDelegate)?
  final public var isRunning: HaishinKit.Atomic<Swift.Bool> {
    get
  }
  final public var expectedMedias: Swift.Set<AVFoundation.AVMediaType>
  final public var audioFormat: AVFAudio.AVAudioFormat? {
    get
    set
  }
  final public var videoFormat: CoreMedia.CMFormatDescription? {
    get
    set
  }
  public init(segmentDuration: Swift.Double = TSWriter.defaultSegmentDuration)
  @objc deinit
}
extension HaishinKit.TSWriter : HaishinKit.IOMuxer {
  final public func append(_ audioBuffer: AVFAudio.AVAudioBuffer, when: AVFAudio.AVAudioTime)
  final public func append(_ sampleBuffer: CoreMedia.CMSampleBuffer)
}
extension HaishinKit.TSWriter : HaishinKit.Running {
  final public func startRunning()
  final public func stopRunning()
}
public protocol IOMuxer : HaishinKit.Running {
  var audioFormat: AVFAudio.AVAudioFormat? { get set }
  var videoFormat: CoreMedia.CMFormatDescription? { get set }
  func append(_ audioBuffer: AVFAudio.AVAudioBuffer, when: AVFAudio.AVAudioTime)
  func append(_ sampleBuffer: CoreMedia.CMSampleBuffer)
}
@available(*, deprecated, renamed: "IOStreamDrawable")
public typealias NetStreamDrawable = HaishinKit.IOStreamDrawable
public protocol IOStreamDrawable : AnyObject {
  @available(tvOS 17.0, *)
  var isCaptureVideoPreviewEnabled: Swift.Bool { get set }
  func attachStream(_ stream: HaishinKit.IOStream?)
  func enqueue(_ sampleBuffer: CoreMedia.CMSampleBuffer?)
}
@objc @_hasMissingDesignatedInitializers final public class NetClient : HaishinKit.NetSocket {
  override final public func listen()
  @objc deinit
}
extension CoreAudioTypes.AudioStreamBasicDescription : Swift.Equatable {
  public static func == (lhs: CoreAudioTypes.AudioStreamBasicDescription, rhs: CoreAudioTypes.AudioStreamBasicDescription) -> Swift.Bool
}
public struct RTMPStreamInfo {
  public var byteCount: HaishinKit.Atomic<Swift.Int64> {
    get
  }
  public var resourceName: Swift.String? {
    get
  }
  public var currentBytesPerSecond: Swift.Int32 {
    get
  }
}
extension HaishinKit.RTMPStreamInfo : Swift.CustomDebugStringConvertible {
  public var debugDescription: Swift.String {
    get
  }
}
@available(tvOS 17.0, *)
public typealias IOVideoCaptureConfigurationBlock = (HaishinKit.IOVideoCaptureUnit?, HaishinKit.IOVideoUnitError?) -> Swift.Void
@_hasMissingDesignatedInitializers @available(tvOS 17.0, *)
final public class IOVideoCaptureUnit {
  public static let colorFormat: Darwin.OSType
  final public var device: AVFoundation.AVCaptureDevice? {
    get
  }
  final public var colorFormat: Darwin.OSType
  final public var isVideoMirrored: Swift.Bool {
    get
    set
  }
  @objc deinit
}
open class RTMPResponder {
  public typealias Handler = (_ data: [Any?]) -> Swift.Void
  public init(result: @escaping HaishinKit.RTMPResponder.Handler, status: HaishinKit.RTMPResponder.Handler? = nil)
  @objc deinit
}
public protocol RTMPConnectionDelegate : AnyObject {
  func connection(_ connection: HaishinKit.RTMPConnection, publishInsufficientBWOccured stream: HaishinKit.RTMPStream)
  func connection(_ connection: HaishinKit.RTMPConnection, publishSufficientBWOccured stream: HaishinKit.RTMPStream)
  func connection(_ connection: HaishinKit.RTMPConnection, updateStats stream: HaishinKit.RTMPStream)
}
public class RTMPConnection : HaishinKit.EventDispatcher {
  public static let defaultWindowSizeS: Swift.Int64
  public static let supportedProtocols: Swift.Set<Swift.String>
  public static let defaultPort: Swift.Int
  public static let defaultSecurePort: Swift.Int
  public static let defaultFlashVer: Swift.String
  public static let defaultChunkSizeS: Swift.Int
  public static let defaultCapabilities: Swift.Int
  public static let defaultObjectEncoding: HaishinKit.RTMPObjectEncoding
  public enum Code : Swift.String {
    case callBadVersion
    case callFailed
    case callProhibited
    case connectAppshutdown
    case connectClosed
    case connectFailed
    case connectIdleTimeOut
    case connectInvalidApp
    case connectNetworkChange
    case connectRejected
    case connectSuccess
    public var level: Swift.String {
      get
    }
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public var swfUrl: Swift.String?
  public var pageUrl: Swift.String?
  public var timeout: Swift.Int
  public var qualityOfService: Dispatch.DispatchQoS
  public var flashVer: Swift.String
  public var chunkSize: Swift.Int
  public var uri: Foundation.URL? {
    get
  }
  public var connected: Swift.Bool {
    get
  }
  public var requireNetworkFramework: Swift.Bool
  public var parameters: Any?
  public var objectEncoding: HaishinKit.RTMPObjectEncoding
  public var totalBytesIn: Swift.Int64 {
    get
  }
  public var totalBytesOut: Swift.Int64 {
    get
  }
  public var totalStreamsCount: Swift.Int {
    get
  }
  weak public var delegate: (any HaishinKit.RTMPConnectionDelegate)?
  @objc dynamic open var previousQueueBytesOut: [Swift.Int64] {
    get
  }
  @objc dynamic open var currentBytesInPerSecond: Swift.Int32 {
    get
  }
  @objc dynamic open var currentBytesOutPerSecond: Swift.Int32 {
    get
  }
  override public init()
  @objc deinit
  public func call(_ commandName: Swift.String, responder: HaishinKit.RTMPResponder?, arguments: Any?...)
  public func connect(_ command: Swift.String, arguments: Any?...)
  public func close()
}
@objc open class RTMPStream : HaishinKit.IOStream {
  public enum Code : Swift.String {
    case bufferEmpty
    case bufferFlush
    case bufferFull
    case connectClosed
    case connectFailed
    case connectRejected
    case connectSuccess
    case drmUpdateNeeded
    case failed
    case multicastStreamReset
    case pauseNotify
    case playFailed
    case playFileStructureInvalid
    case playInsufficientBW
    case playNoSupportedTrackFound
    case playReset
    case playStart
    case playStop
    case playStreamNotFound
    case playTransition
    case playUnpublishNotify
    case publishBadName
    case publishIdle
    case publishStart
    case recordAlreadyExists
    case recordFailed
    case recordNoAccess
    case recordStart
    case recordStop
    case recordDiskQuotaExceeded
    case secondScreenStart
    case secondScreenStop
    case seekFailed
    case seekInvalidTime
    case seekNotify
    case stepNotify
    case unpauseNotify
    case unpublishSuccess
    case videoDimensionChange
    public var level: Swift.String {
      get
    }
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public enum HowToPublish : Swift.String {
    case record
    case append
    case appendWithGap
    case live
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public var metadata: [Swift.String : Any?] {
    get
  }
  public var info: HaishinKit.RTMPStreamInfo {
    get
  }
  public var objectEncoding: HaishinKit.RTMPObjectEncoding {
    get
  }
  public var audioSampleAccess: Swift.Bool {
    get
  }
  public var videoSampleAccess: Swift.Bool {
    get
  }
  public var receiveAudio: Swift.Bool {
    get
    set
  }
  public var receiveVideo: Swift.Bool {
    get
    set
  }
  public var paused: Swift.Bool {
    get
    set
  }
  public init(connection: HaishinKit.RTMPConnection)
  @objc deinit
  public func play(_ arguments: Any?...)
  public func seek(_ offset: Swift.Double)
  public func publish(_ name: Swift.String?, type: HaishinKit.RTMPStream.HowToPublish = .live)
  public func close()
  public func send(handlerName: Swift.String, arguments: Any?...)
  open func makeMetaData() -> HaishinKit.ASObject
  override public func readyStateWillChange(to readyState: HaishinKit.IOStream.ReadyState)
  override public func readyStateDidChange(to readyState: HaishinKit.IOStream.ReadyState)
}
extension HaishinKit.RTMPStream : HaishinKit.EventDispatcherConvertible {
  public func addEventListener(_ type: HaishinKit.Event.Name, selector: ObjectiveC.Selector, observer: Swift.AnyObject? = nil, useCapture: Swift.Bool = false)
  public func removeEventListener(_ type: HaishinKit.Event.Name, selector: ObjectiveC.Selector, observer: Swift.AnyObject? = nil, useCapture: Swift.Bool = false)
  public func dispatch(event: HaishinKit.Event)
  public func dispatch(_ type: HaishinKit.Event.Name, bubbles: Swift.Bool, data: Any?)
}
@objc @_inheritsConvenienceInitializers @_Concurrency.MainActor(unsafe) public class PiPHKView : UIKit.UIView {
  @_Concurrency.MainActor(unsafe) public static var defaultBackgroundColor: UIKit.UIColor
  @_Concurrency.MainActor(unsafe) @objc override dynamic public class var layerClass: Swift.AnyClass {
    @objc get
  }
  @_Concurrency.MainActor(unsafe) @objc override dynamic public var layer: AVFoundation.AVSampleBufferDisplayLayer {
    @objc get
  }
  @_Concurrency.MainActor(unsafe) public var videoGravity: AVFoundation.AVLayerVideoGravity {
    get
    set
  }
  @available(tvOS 17.0, *)
  @_Concurrency.MainActor(unsafe) public var isCaptureVideoPreviewEnabled: Swift.Bool {
    get
    set
  }
  @_Concurrency.MainActor(unsafe) @objc override dynamic public init(frame: CoreFoundation.CGRect)
  @_Concurrency.MainActor(unsafe) @objc required dynamic public init?(coder aDecoder: Foundation.NSCoder)
  @objc deinit
  @_Concurrency.MainActor(unsafe) @objc override dynamic public func awakeFromNib()
}
extension HaishinKit.PiPHKView : HaishinKit.IOStreamDrawable {
  @_Concurrency.MainActor(unsafe) public func attachStream(_ stream: HaishinKit.IOStream?)
  @_Concurrency.MainActor(unsafe) public func enqueue(_ sampleBuffer: CoreMedia.CMSampleBuffer?)
}
public enum RTMPObjectEncoding : Swift.UInt8 {
  case amf0
  case amf3
  public init?(rawValue: Swift.UInt8)
  public typealias RawValue = Swift.UInt8
  public var rawValue: Swift.UInt8 {
    get
  }
}
public protocol IORecorderDelegate : AnyObject {
  func recorder(_ recorder: HaishinKit.IORecorder, errorOccured error: HaishinKit.IORecorder.Error)
  func recorder(_ recorder: HaishinKit.IORecorder, finishWriting writer: AVFoundation.AVAssetWriter)
}
@_hasMissingDesignatedInitializers final public class IORecorder {
  public enum Error : Swift.Error {
    case failedToCreateAssetWriter(error: any Swift.Error)
    case failedToCreateAssetWriterInput(error: Foundation.NSException)
    case failedToAppend(error: (any Swift.Error)?)
    case failedToFinishWriting(error: (any Swift.Error)?)
  }
  public static let defaultOutputSettings: [AVFoundation.AVMediaType : [Swift.String : Any]]
  weak final public var delegate: (any HaishinKit.IORecorderDelegate)?
  final public var outputSettings: [AVFoundation.AVMediaType : [Swift.String : Any]]
  final public var isRunning: HaishinKit.Atomic<Swift.Bool> {
    get
  }
  final public func append(_ sampleBuffer: CoreMedia.CMSampleBuffer)
  final public func append(_ pixelBuffer: CoreVideo.CVPixelBuffer, withPresentationTime: CoreMedia.CMTime)
  @objc deinit
}
extension HaishinKit.IORecorder : HaishinKit.Running {
  final public func startRunning()
  final public func stopRunning()
}
@available(*, deprecated, renamed: "IOVideoMixerSettings")
public typealias MultiCamCaptureSettings = HaishinKit.IOVideoMixerSettings
public struct IOVideoMixerSettings : Swift.Codable {
  public enum Mode : Swift.String, Swift.Codable {
    case pip
    case splitView
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public static let `default`: HaishinKit.IOVideoMixerSettings
  public let mode: HaishinKit.IOVideoMixerSettings.Mode
  public let cornerRadius: CoreFoundation.CGFloat
  public let regionOfInterest: CoreFoundation.CGRect
  public let direction: HaishinKit.ImageTransform
  public var channel: Swift.UInt8
  public init(mode: HaishinKit.IOVideoMixerSettings.Mode, cornerRadius: CoreFoundation.CGFloat, regionOfInterest: CoreFoundation.CGRect, direction: HaishinKit.ImageTransform)
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
public protocol IOScreenCaptureUnitDelegate : AnyObject {
  func session(_ session: any HaishinKit.IOScreenCaptureUnit, didOutput pixelBuffer: CoreVideo.CVPixelBuffer, presentationTime: CoreMedia.CMTime)
}
public protocol IOScreenCaptureUnit : HaishinKit.Running {
  var attributes: [Foundation.NSString : ObjectiveC.NSObject] { get }
  var delegate: (any HaishinKit.IOScreenCaptureUnitDelegate)? { get set }
}
public struct VTSessionOption {
}
extension HaishinKit.VTSessionOption : Swift.Hashable {
  public static func == (lhs: HaishinKit.VTSessionOption, rhs: HaishinKit.VTSessionOption) -> Swift.Bool
  public func hash(into hasher: inout Swift.Hasher)
  public var hashValue: Swift.Int {
    get
  }
}
public protocol Running : AnyObject {
  var isRunning: HaishinKit.Atomic<Swift.Bool> { get }
  func startRunning()
  func stopRunning()
}
public class ByteArray {
  public enum Error : Swift.Error {
    case eof
    case parse
    public static func == (a: HaishinKit.ByteArray.Error, b: HaishinKit.ByteArray.Error) -> Swift.Bool
    public func hash(into hasher: inout Swift.Hasher)
    public var hashValue: Swift.Int {
      get
    }
  }
  public init()
  public init(data: Foundation.Data)
  public var length: Swift.Int {
    get
    set
  }
  public var position: Swift.Int
  public var bytesAvailable: Swift.Int {
    get
  }
  public subscript(i: Swift.Int) -> Swift.UInt8 {
    get
    set
  }
  public func readUInt8() throws -> Swift.UInt8
  @discardableResult
  public func writeUInt8(_ value: Swift.UInt8) -> Self
  public func readInt8() throws -> Swift.Int8
  @discardableResult
  public func writeInt8(_ value: Swift.Int8) -> Self
  public func readUInt16() throws -> Swift.UInt16
  @discardableResult
  public func writeUInt16(_ value: Swift.UInt16) -> Self
  public func readInt16() throws -> Swift.Int16
  @discardableResult
  public func writeInt16(_ value: Swift.Int16) -> Self
  public func readUInt24() throws -> Swift.UInt32
  @discardableResult
  public func writeUInt24(_ value: Swift.UInt32) -> Self
  public func readUInt32() throws -> Swift.UInt32
  @discardableResult
  public func writeUInt32(_ value: Swift.UInt32) -> Self
  public func readInt32() throws -> Swift.Int32
  @discardableResult
  public func writeInt32(_ value: Swift.Int32) -> Self
  @discardableResult
  public func writeUInt64(_ value: Swift.UInt64) -> Self
  public func readUInt64() throws -> Swift.UInt64
  public func writeInt64(_ value: Swift.Int64) -> Self
  public func readInt64() throws -> Swift.Int64
  public func readDouble() throws -> Swift.Double
  @discardableResult
  public func writeDouble(_ value: Swift.Double) -> Self
  public func readFloat() throws -> Swift.Float
  @discardableResult
  public func writeFloat(_ value: Swift.Float) -> Self
  public func readUTF8() throws -> Swift.String
  @discardableResult
  public func writeUTF8(_ value: Swift.String) throws -> Self
  @discardableResult
  public func clear() -> Self
  @objc deinit
}
extension HaishinKit.ByteArray : Swift.CustomDebugStringConvertible {
  public var debugDescription: Swift.String {
    get
  }
}
@objc @_inheritsConvenienceInitializers open class VideoEffect : ObjectiveC.NSObject {
  public var ciContext: CoreImage.CIContext?
  open func execute(_ image: CoreImage.CIImage, info: CoreMedia.CMSampleBuffer?) -> CoreImage.CIImage
  @objc override dynamic public init()
  @objc deinit
}
public struct VideoCodecSettings : Swift.Codable {
  public static let frameInterval30: Swift.Double
  public static let frameInterval10: Swift.Double
  public static let frameInterval05: Swift.Double
  public static let frameInterval01: Swift.Double
  public static let `default`: HaishinKit.VideoCodecSettings
  public enum BitRateMode : Swift.String, Swift.Codable {
    case average
    @available(iOS 16.0, tvOS 16.0, macOS 13.0, *)
    case constant
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public enum ScalingMode : Swift.String, Swift.Codable {
    case normal
    case letterbox
    case cropSourceToCleanAperture
    case trim
    public init?(rawValue: Swift.String)
    public typealias RawValue = Swift.String
    public var rawValue: Swift.String {
      get
    }
  }
  public var videoSize: CoreFoundation.CGSize
  public var bitRate: Swift.Int
  public var profileLevel: Swift.String {
    get
    set
  }
  public var scalingMode: HaishinKit.VideoCodecSettings.ScalingMode
  public var bitRateMode: HaishinKit.VideoCodecSettings.BitRateMode
  public var maxKeyFrameIntervalDuration: Swift.Int32
  public var allowFrameReordering: Swift.Bool?
  public var dataRateLimits: [Swift.Double]?
  public var isHardwareEncoderEnabled: Swift.Bool
  public var frameInterval: Swift.Double
  public init(videoSize: CoreFoundation.CGSize = .init(width: 854, height: 480), bitRate: Swift.Int = 640 * 1000, profileLevel: Swift.String = kVTProfileLevel_H264_Baseline_3_1 as String, scalingMode: HaishinKit.VideoCodecSettings.ScalingMode = .trim, bitRateMode: HaishinKit.VideoCodecSettings.BitRateMode = .average, maxKeyFrameIntervalDuration: Swift.Int32 = 2, allowFrameReordering: Swift.Bool? = nil, dataRateLimits: [Swift.Double]? = [0.0, 0.0], isHardwareEncoderEnabled: Swift.Bool = true)
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
public protocol EventDispatcherConvertible : AnyObject {
  func addEventListener(_ type: HaishinKit.Event.Name, selector: ObjectiveC.Selector, observer: Swift.AnyObject?, useCapture: Swift.Bool)
  func removeEventListener(_ type: HaishinKit.Event.Name, selector: ObjectiveC.Selector, observer: Swift.AnyObject?, useCapture: Swift.Bool)
  func dispatch(event: HaishinKit.Event)
  func dispatch(_ type: HaishinKit.Event.Name, bubbles: Swift.Bool, data: Any?)
}
final public class Event {
  public struct Name : Swift.RawRepresentable, Swift.ExpressibleByStringLiteral {
    public typealias RawValue = Swift.String
    public typealias StringLiteralType = Swift.String
    public static let sync: HaishinKit.Event.Name
    public static let event: HaishinKit.Event.Name
    public static let ioError: HaishinKit.Event.Name
    public static let rtmpStatus: HaishinKit.Event.Name
    public let rawValue: Swift.String
    public init(rawValue: Swift.String)
    public init(stringLiteral value: Swift.String)
    public typealias ExtendedGraphemeClusterLiteralType = HaishinKit.Event.Name.StringLiteralType
    public typealias UnicodeScalarLiteralType = HaishinKit.Event.Name.StringLiteralType
  }
  public static func from(_ notification: Foundation.Notification) -> HaishinKit.Event
  final public var type: HaishinKit.Event.Name {
    get
  }
  final public var bubbles: Swift.Bool {
    get
  }
  final public var data: Any? {
    get
  }
  final public var target: Swift.AnyObject? {
    get
  }
  public init(type: HaishinKit.Event.Name, bubbles: Swift.Bool = false, data: Any? = nil)
  @objc deinit
}
extension HaishinKit.Event : Swift.CustomDebugStringConvertible {
  final public var debugDescription: Swift.String {
    get
  }
}
public class EventDispatcher : HaishinKit.EventDispatcherConvertible {
  public init()
  public init(target: Swift.AnyObject)
  @objc deinit
  public func addEventListener(_ type: HaishinKit.Event.Name, selector: ObjectiveC.Selector, observer: Swift.AnyObject? = nil, useCapture: Swift.Bool = false)
  public func removeEventListener(_ type: HaishinKit.Event.Name, selector: ObjectiveC.Selector, observer: Swift.AnyObject? = nil, useCapture: Swift.Bool = false)
  open func dispatch(event: HaishinKit.Event)
  public func dispatch(_ type: HaishinKit.Event.Name, bubbles: Swift.Bool, data: Any?)
}
@objc open class NetService : ObjectiveC.NSObject {
  open var txtData: Foundation.Data? {
    get
  }
  final public let domain: Swift.String
  final public let type: Swift.String
  final public let name: Swift.String
  final public let port: Swift.Int32
  public var isRunning: HaishinKit.Atomic<Swift.Bool> {
    get
  }
  public var clients: [HaishinKit.NetClient] {
    get
  }
  public init(domain: Swift.String, type: Swift.String, name: Swift.String, port: Swift.Int32)
  @objc deinit
}
extension HaishinKit.NetService : Foundation.NetServiceDelegate {
  @objc dynamic public func netService(_ sender: Foundation.NetService, didAcceptConnectionWith inputStream: Foundation.InputStream, outputStream: Foundation.OutputStream)
}
extension HaishinKit.NetService : HaishinKit.Running {
  public func startRunning()
  public func stopRunning()
}
@objc @_inheritsConvenienceInitializers open class NetSocket : ObjectiveC.NSObject {
  public static let defaultTimeout: Swift.Int
  public static let defaultWindowSizeC: Swift.Int
  public static let defaultQualityOfService: Dispatch.DispatchQoS
  public var inputBuffer: Foundation.Data
  public var timeout: Swift.Int
  public var connected: Swift.Bool
  public var windowSizeC: Swift.Int
  public var totalBytesIn: HaishinKit.Atomic<Swift.Int64>
  public var qualityOfService: Dispatch.DispatchQoS
  public var securityLevel: Foundation.StreamSocketSecurityLevel
  public var outputBufferSize: Swift.Int
  public var totalBytesOut: HaishinKit.Atomic<Swift.Int64> {
    get
  }
  public var queueBytesOut: HaishinKit.Atomic<Swift.Int64> {
    get
  }
  @objc deinit
  public func connect(withName: Swift.String, port: Swift.Int)
  @discardableResult
  public func doOutput(data: Foundation.Data, locked: Swift.UnsafeMutablePointer<Swift.UInt32>? = nil) -> Swift.Int
  open func close()
  open func listen()
  @objc override dynamic public init()
}
extension HaishinKit.NetSocket : Foundation.StreamDelegate {
  @objc dynamic public func stream(_ aStream: Foundation.Stream, handle eventCode: Foundation.Stream.Event)
}
@available(*, deprecated, renamed: "IOStreamBitRateStats")
public typealias NetBitRateStats = HaishinKit.IOStreamBitRateStats
public struct IOStreamBitRateStats {
  public let currentQueueBytesOut: Swift.Int64
  public let currentBytesInPerSecond: Swift.Int32
  public let currentBytesOutPerSecond: Swift.Int32
}
@available(*, deprecated, renamed: "IOStreamBitRateStats")
public typealias NetBitRateStrategyConvertible = HaishinKit.IOStreamBitRateStrategyConvertible
public protocol IOStreamBitRateStrategyConvertible : AnyObject {
  var stream: HaishinKit.IOStream? { get set }
  var mamimumVideoBitRate: Swift.Int { get }
  var mamimumAudioBitRate: Swift.Int { get }
  func setUp()
  func sufficientBWOccured(_ stats: HaishinKit.IOStreamBitRateStats)
  func insufficientBWOccured(_ stats: HaishinKit.IOStreamBitRateStats)
}
@available(*, deprecated, renamed: "IOStreamBitRateStrategy")
public typealias NetBitRateStrategy = HaishinKit.IOStreamBitRateStrategy
@_hasMissingDesignatedInitializers final public class IOStreamBitRateStrategy : HaishinKit.IOStreamBitRateStrategyConvertible {
  public static let shared: HaishinKit.IOStreamBitRateStrategy
  weak final public var stream: HaishinKit.IOStream?
  final public let mamimumVideoBitRate: Swift.Int
  final public let mamimumAudioBitRate: Swift.Int
  final public func setUp()
  final public func sufficientBWOccured(_ stats: HaishinKit.IOStreamBitRateStats)
  final public func insufficientBWOccured(_ stats: HaishinKit.IOStreamBitRateStats)
  @objc deinit
}
@available(*, deprecated, renamed: "IOStreamVideoAdaptiveNetBitRateStrategy")
public typealias VideoAdaptiveNetBitRateStrategy = HaishinKit.IOStreamVideoAdaptiveNetBitRateStrategy
final public class IOStreamVideoAdaptiveNetBitRateStrategy : HaishinKit.IOStreamBitRateStrategyConvertible {
  public static let sufficientBWCountsThreshold: Swift.Int
  weak final public var stream: HaishinKit.IOStream?
  final public let mamimumVideoBitRate: Swift.Int
  final public let mamimumAudioBitRate: Swift.Int
  public init(mamimumVideoBitrate: Swift.Int)
  final public func setUp()
  final public func sufficientBWOccured(_ stats: HaishinKit.IOStreamBitRateStats)
  final public func insufficientBWOccured(_ stats: HaishinKit.IOStreamBitRateStats)
  @objc deinit
}
public class InstanceHolder<T> where T : Swift.Equatable {
  public init(factory: @escaping () -> T)
  public func retain() -> T?
  public func release(_ instance: T?)
  @objc deinit
}
public struct AudioCodecSettings : Swift.Codable {
  public static let `default`: HaishinKit.AudioCodecSettings
  public static let maximumNumberOfChannels: Swift.UInt32
  public static let mamimumSampleRate: Swift.Double
  public var bitRate: Swift.Int
  public var sampleRate: Swift.Float64
  public var channels: Swift.UInt32
  public var downmix: Swift.Bool
  public var channelMap: [Swift.Int]?
  public init(bitRate: Swift.Int = 64 * 1000, sampleRate: Swift.Float64 = 0, channels: Swift.UInt32 = 0, downmix: Swift.Bool = false, channelMap: [Swift.Int]? = nil)
  public func encode(to encoder: any Swift.Encoder) throws
  public init(from decoder: any Swift.Decoder) throws
}
public struct Atomic<A> {
  public var value: A {
    get
  }
  public init(_ value: A)
  public mutating func mutate(_ transform: (inout A) -> Swift.Void)
}
public enum ImageTransform : Swift.String, Swift.Codable {
  case north
  case south
  case east
  case west
  public init?(rawValue: Swift.String)
  public typealias RawValue = Swift.String
  public var rawValue: Swift.String {
    get
  }
}
public enum IOAudioUnitError : Swift.Error {
  case failedToCreate(from: AVFAudio.AVAudioFormat?, to: AVFAudio.AVAudioFormat?)
  case failedToConvert(error: Foundation.NSError)
}
extension HaishinKit.RTMPConnection.Code : Swift.Equatable {}
extension HaishinKit.RTMPConnection.Code : Swift.Hashable {}
extension HaishinKit.RTMPConnection.Code : Swift.RawRepresentable {}
extension HaishinKit.RTMPStream.Code : Swift.Equatable {}
extension HaishinKit.RTMPStream.Code : Swift.Hashable {}
extension HaishinKit.RTMPStream.Code : Swift.RawRepresentable {}
extension HaishinKit.RTMPStream.HowToPublish : Swift.Equatable {}
extension HaishinKit.RTMPStream.HowToPublish : Swift.Hashable {}
extension HaishinKit.RTMPStream.HowToPublish : Swift.RawRepresentable {}
extension HaishinKit.RTMPObjectEncoding : Swift.Equatable {}
extension HaishinKit.RTMPObjectEncoding : Swift.Hashable {}
extension HaishinKit.RTMPObjectEncoding : Swift.RawRepresentable {}
extension HaishinKit.IOVideoMixerSettings.Mode : Swift.Equatable {}
extension HaishinKit.IOVideoMixerSettings.Mode : Swift.Hashable {}
extension HaishinKit.IOVideoMixerSettings.Mode : Swift.RawRepresentable {}
extension HaishinKit.ByteArray.Error : Swift.Equatable {}
extension HaishinKit.ByteArray.Error : Swift.Hashable {}
extension HaishinKit.VideoCodecSettings.BitRateMode : Swift.Equatable {}
extension HaishinKit.VideoCodecSettings.BitRateMode : Swift.Hashable {}
extension HaishinKit.VideoCodecSettings.BitRateMode : Swift.RawRepresentable {}
extension HaishinKit.VideoCodecSettings.ScalingMode : Swift.Equatable {}
extension HaishinKit.VideoCodecSettings.ScalingMode : Swift.Hashable {}
extension HaishinKit.VideoCodecSettings.ScalingMode : Swift.RawRepresentable {}
extension HaishinKit.ImageTransform : Swift.Equatable {}
extension HaishinKit.ImageTransform : Swift.Hashable {}
extension HaishinKit.ImageTransform : Swift.RawRepresentable {}
